{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  \n",
    "  \n",
    "import numpy as np  \n",
    "import torch  \n",
    "from torch.utils.data import Dataset,DataLoader  \n",
    "  \n",
    "# 定义字典  \n",
    "words_x = '<PAD>,1,2,3,4,5,6,7,8,9,0,<SOS>,<EOS>,+'  \n",
    "vocab_x = {word: i for i, word in enumerate(words_x.split(','))}  \n",
    "vocab_xr = [k for k, v in vocab_x.items()] #反查词典  \n",
    "  \n",
    "words_y = '<PAD>,1,2,3,4,5,6,7,8,9,0,<SOS>,<EOS>'  \n",
    "vocab_y = {word: i for i, word in enumerate(words_y.split(','))}  \n",
    "vocab_yr = [k for k, v in vocab_y.items()] #反查词典  \n",
    "#两数相加数据集  \n",
    "def get_data():  \n",
    "    # 定义词集合  \n",
    "    words = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']  \n",
    "  \n",
    "    # 每个词被选中的概率  \n",
    "    p = np.array([7, 5, 5, 7, 6, 5, 7, 6, 5, 7])  \n",
    "    p = p / p.sum()  \n",
    "  \n",
    "    # 随机采样n1个词作为s1  \n",
    "    n1 = random.randint(10, 20)  \n",
    "    s1 = np.random.choice(words, size=n1, replace=True, p=p)  \n",
    "    s1 = s1.tolist()  \n",
    "  \n",
    "    # 随机采样n2个词作为s2  \n",
    "    n2 = random.randint(10, 20)  \n",
    "    s2 = np.random.choice(words, size=n2, replace=True, p=p)  \n",
    "    s2 = s2.tolist()  \n",
    "  \n",
    "    # x等于s1和s2字符上的相加  \n",
    "    x = s1 + ['+'] + s2  \n",
    "      \n",
    "    # y等于s1和s2数值上的相加  \n",
    "    y = int(''.join(s1)) + int(''.join(s2))  \n",
    "    y = list(str(y))  \n",
    "      \n",
    "    # 加上首尾符号  \n",
    "    x = ['<SOS>'] + x + ['<EOS>']  \n",
    "    y = ['<SOS>'] + y + ['<EOS>']  \n",
    "  \n",
    "    # 补pad到固定长度  \n",
    "    x = x + ['<PAD>'] * 50\n",
    "    y = y + ['<PAD>'] * 51\n",
    "    x = x[:50]\n",
    "    y = y[:51]\n",
    "  \n",
    "    # 编码成token  \n",
    "    token_x = [vocab_x[i] for i in x]  \n",
    "    token_y = [vocab_y[i] for i in y]  \n",
    "  \n",
    "    # 转tensor  \n",
    "    tensor_x = torch.LongTensor(token_x)  \n",
    "    tensor_y = torch.LongTensor(token_y)  \n",
    "    return tensor_x, tensor_y  \n",
    "  \n",
    "  \n",
    "def show_data(tensor_x,tensor_y) ->\"str\":  \n",
    "    words_x = \"\".join([vocab_xr[i] for i in tensor_x.tolist()])  \n",
    "    words_y = \"\".join([vocab_yr[i] for i in tensor_y.tolist()])  \n",
    "    return words_x,words_y  \n",
    "  \n",
    "  \n",
    "x,y = get_data()   \n",
    "print(x.shape,y.shape,\"\\n\")  \n",
    "print(show_data(x,y))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader  \n",
    "\n",
    "word = '<PAD>,1,2,3,4,5,6,7,8,9,0,<SOS>,<EOS>,;'\n",
    "vocab = {word: i for i, word in enumerate(word.split(','))} \n",
    "vocab_r = [k for k, v in vocab.items()] #反查词典  \n",
    "\n",
    "def get_data():\n",
    "    num_to_be_sort = 10\n",
    "    maxnum = 1000\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for i in range(num_to_be_sort):\n",
    "        x_list.append(np.random.randint(0,maxnum))\n",
    "    y_list = sorted(x_list)\n",
    "    \n",
    "\n",
    "    x = ''\n",
    "    y = ''\n",
    "\n",
    "    for i in range(num_to_be_sort):\n",
    "        x = x+str(x_list[i]) + ';'\n",
    "        y = y+str(y_list[i]) + ';'\n",
    "    x =x[:-1]\n",
    "    y = y[:-1]\n",
    "\n",
    "    x = [ch for ch in x]\n",
    "    y = [ch for ch in y]\n",
    "\n",
    "    x = ['<SOS>'] + x + ['<EOS>']\n",
    "    y = ['<SOS>'] + y + ['<EOS>']\n",
    "\n",
    "    x = x + ['<PAD>'] * 50\n",
    "    y = y + ['<PAD>'] * 51\n",
    "    x = x[:50]\n",
    "    y = y[:51]\n",
    "\n",
    "    token_x = [vocab[i] for i in x]\n",
    "    token_y = [vocab[i] for i in y]\n",
    "\n",
    "    tensor_x = torch.LongTensor(token_x)\n",
    "    tensor_y = torch.LongTensor(token_y)\n",
    "\n",
    "    return tensor_x.to(device), tensor_y.to(device)\n",
    "\n",
    "def show_data(tensor_x,tensor_y):\n",
    "    word_x = \"\".join([vocab_r[i] for i in tensor_x.tolist()])\n",
    "    word_y = \"\".join([vocab_r[i] for i in tensor_y.tolist()])\n",
    "    return word_x, word_y\n",
    "\n",
    "x, y = get_data()\n",
    "print(x.shape,y.shape)\n",
    "show_data(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据集  \n",
    "class TwoSumDataset(torch.utils.data.Dataset):  \n",
    "    def __init__(self,size = 100000):  \n",
    "        super(Dataset, self).__init__()  \n",
    "        self.size = size  \n",
    "  \n",
    "    def __len__(self):  \n",
    "        return self.size  \n",
    "  \n",
    "    def __getitem__(self, i):  \n",
    "        return get_data()  \n",
    "      \n",
    "ds_train = TwoSumDataset(size = 100000)  \n",
    "ds_val = TwoSumDataset(size = 10000)  \n",
    "  \n",
    "  \n",
    "# 数据加载器  \n",
    "dl_train = DataLoader(dataset=ds_train,  \n",
    "         batch_size=200,  \n",
    "         drop_last=True,  \n",
    "         shuffle=True)  \n",
    "  \n",
    "dl_val = DataLoader(dataset=ds_val,  \n",
    "         batch_size=200,  \n",
    "         drop_last=True,  \n",
    "         shuffle=False)  \n",
    "  \n",
    "for src,tgt in dl_train:  \n",
    "    print(src.shape)  \n",
    "    print(tgt.shape)  \n",
    "    break   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "from torch import nn   \n",
    "import torch.nn.functional as F  \n",
    "import copy   \n",
    "import math   \n",
    "import numpy as np  \n",
    "import pandas as pd   \n",
    "  \n",
    "def clones(module, N):  \n",
    "    \"Produce N identical layers.\"  \n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):  \n",
    "    \"Compute 'Scaled Dot Product Attention'\"  \n",
    "    def __init__(self):  \n",
    "        super(ScaledDotProductAttention, self).__init__()  \n",
    "  \n",
    "    def forward(self,query, key, value, mask=None, dropout=None):  \n",
    "        d_k = query.size(-1)  \n",
    "        scores = query@key.transpose(-2,-1) / math.sqrt(d_k)       \n",
    "        if mask is not None:  \n",
    "            scores = scores.masked_fill(mask == 0, -1e20)  \n",
    "        p_attn = F.softmax(scores, dim = -1)  \n",
    "        if dropout is not None:  \n",
    "            p_attn = dropout(p_attn)  \n",
    "        return p_attn@value, p_attn  \n",
    "      \n",
    "class MultiHeadAttention(nn.Module):  \n",
    "    def __init__(self, h, d_model, dropout=0.1):  \n",
    "        \"Take in model size and number of heads.\"  \n",
    "        super(MultiHeadAttention, self).__init__()  \n",
    "        assert d_model % h == 0  \n",
    "        # We assume d_v always equals d_k  \n",
    "        self.d_k = d_model // h  \n",
    "        self.h = h  \n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)  \n",
    "        self.attn = None #记录 attention矩阵结果  \n",
    "        self.dropout = nn.Dropout(p=dropout)  \n",
    "        self.attention = ScaledDotProductAttention()  \n",
    "          \n",
    "    def forward(self, query, key, value, mask=None):  \n",
    "        if mask is not None:  \n",
    "            # Same mask applied to all h heads.  \n",
    "            mask = mask.unsqueeze(1)  \n",
    "        nbatches = query.size(0)  \n",
    "          \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k   \n",
    "        query, key, value = [  \n",
    "            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)  \n",
    "             for l, x in zip(self.linears, (query, key, value))  \n",
    "        ]  \n",
    "          \n",
    "        # 2) Apply attention on all the projected vectors in batch.   \n",
    "        x, self.attn = self.attention(query, key, value, mask=mask,   \n",
    "                                 dropout=self.dropout)  \n",
    "          \n",
    "        # 3) \"Concat\" using a view and apply a final linear.   \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)  \n",
    "        return self.linears[-1](x)  \n",
    "  \n",
    "  \n",
    "#为了让训练过程与解码过程信息流一致，遮挡tgt序列后面元素，设置其注意力为0  \n",
    "def tril_mask(data):  \n",
    "    \"Mask out future positions.\"  \n",
    "    size = data.size(-1) #size为序列长度  \n",
    "    full = torch.full((1,size,size),1,dtype=torch.int,device=data.device)  \n",
    "    mask = torch.tril(full).bool()   \n",
    "    return mask  \n",
    "  \n",
    "  \n",
    "#设置对<PAD>的注意力为0  \n",
    "def pad_mask(data, pad=0):  \n",
    "    \"Mask out pad positions.\"  \n",
    "    mask = (data!=pad).unsqueeze(-2)  \n",
    "    return mask   \n",
    "  \n",
    "  \n",
    "#计算一个batch数据的src_mask和tgt_mask  \n",
    "class MaskedBatch:  \n",
    "    \"Object for holding a batch of data with mask during training.\"  \n",
    "    def __init__(self, src, tgt=None, pad=0):  \n",
    "        self.src = src  \n",
    "        self.src_mask = pad_mask(src,pad)  \n",
    "        if tgt is not None:  \n",
    "            self.tgt = tgt[:,:-1] #训练时,拿tgt的每一个词输入,去预测下一个词,所以最后一个词无需输入  \n",
    "            self.tgt_y = tgt[:, 1:] #第一个总是<SOS>无需预测，预测从第二个词开始  \n",
    "            self.tgt_mask = \\\n",
    "                self.make_tgt_mask(self.tgt, pad)  \n",
    "            self.ntokens = (self.tgt_y!= pad).sum()   \n",
    "      \n",
    "    @staticmethod  \n",
    "    def make_tgt_mask(tgt, pad):  \n",
    "        \"Create a mask to hide padding and future words.\"  \n",
    "        tgt_pad_mask = pad_mask(tgt,pad)  \n",
    "        tgt_tril_mask = tril_mask(tgt)  \n",
    "        tgt_mask = tgt_pad_mask & (tgt_tril_mask)  \n",
    "        return tgt_mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tril_mask(data):  \n",
    "    \"Mask out future positions.\"  \n",
    "    size = data.size(-1) #size为序列长度  \n",
    "    full = torch.full((1,size,size),1,dtype=torch.int,device=data.device)  \n",
    "    mask = torch.tril(full).bool()   \n",
    "    return mask  \n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_mask = (src != vocab['<PAD>']).unsqueeze(-2)\n",
    "    tgt_mask = (tgt != vocab['<PAD>']).unsqueeze(-2)\n",
    "    tgt_len = tgt.shape[-1]\n",
    "    tgt_mask = tgt_mask & torch.tril(torch.ones(1,tgt_len, tgt_len,device=device)).bool()\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px   \n",
    "# 测试tril_mask   \n",
    "# mask = tril_mask(torch.zeros(1,10)) #序列长度为10  \n",
    "\n",
    "# test create_mask\n",
    "_,mask = create_mask(torch.ones(1,10,device=device),torch.ones(1,10,device=device))\n",
    "mask = mask.to('cpu')\n",
    "#sns.heatmap(mask[0],cmap=sns.cm.rocket);  \n",
    "px.imshow(mask[0],color_continuous_scale=\"blues\",height=600,width=600)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(attn, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V,mask=None,dropout=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(K.size(-1))\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        p_attn = F.softmax(scores, dim = -1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return p_attn.matmul(V), p_attn\n",
    "\n",
    "class multihead_attn(nn.Module):\n",
    "    def __init__(self, n_heads, input_dim, dropout=0.1):\n",
    "        super(multihead_attn, self).__init__()\n",
    "        assert input_dim % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.input_dim = input_dim\n",
    "        self.dim_each_head = input_dim // n_heads\n",
    "        self.WQ = nn.Linear(input_dim, input_dim)\n",
    "        self.WK = nn.Linear(input_dim, input_dim)\n",
    "        self.WV = nn.Linear(input_dim, input_dim)\n",
    "        self.WO = nn.Linear(input_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn = attn()\n",
    "        self.matrix = None\n",
    "\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.shape[0]\n",
    "        seq_len = Q.shape[1]\n",
    "        input_dim = Q.shape[2]\n",
    "        Q = self.WQ(Q)\n",
    "        K = self.WK(K)\n",
    "        V = self.WV(V)\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.dim_each_head).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.dim_each_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.dim_each_head).transpose(1, 2)\n",
    "        attn_score, self.matrix = self.attn(Q, K, V, mask,dropout=self.dropout)\n",
    "\n",
    "        output = attn_score.transpose(1, 2).contiguous().view(batch_size, seq_len, input_dim)\n",
    "        return self.WO(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试 ScaledDotProductAttention  \n",
    "  \n",
    "query = torch.tensor([[[0.0,1.414],[1.414,0.0],[1.0,1.0],[-1.0,1.0],[1.0,-1.0]]])  \n",
    "key = query.clone()   \n",
    "value = query.clone()  \n",
    "  \n",
    "# attention = ScaledDotProductAttention()  \n",
    "\n",
    "# test attn\n",
    "attention = attn()\n",
    "  \n",
    "#没有mask   \n",
    "out,p_attn = attention(query, key, value)  \n",
    "\n",
    "fig = px.imshow(p_attn[0],color_continuous_scale=\"blues\",  \n",
    "                title=\"without mask\",height=600,width=600)  \n",
    "fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#考虑mask  \n",
    "out,p_att = attention(query, key, value, mask = tril_mask(torch.zeros(3,5)))  \n",
    "fig = px.imshow(p_attn[0],color_continuous_scale=\"blues\",  \n",
    "                height=600,width=600,  \n",
    "                title=\"with mask\")  \n",
    "fig.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试MultiHeadAttention  \n",
    "# cross_attn = MultiHeadAttention(h=2, d_model=4)  \n",
    "cross_attn = multihead_attn(n_heads=2,input_dim=4)\n",
    "cross_attn.eval()  \n",
    "q1 = torch.tensor([[[0.1,0.1,0.1,0.1],[0.1,0.3,0.1,0.3]]])  \n",
    "k1 = q1.clone()  \n",
    "v1 = q1.clone()  \n",
    "tgt_mask = tril_mask(torch.zeros(2,2))  \n",
    "  \n",
    "out1 = cross_attn.forward(q1,k1,v1,mask = tgt_mask)  \n",
    "print(\"out1:\\n\",out1)  \n",
    "  \n",
    "#改变序列的第2个元素取值，由于有mask的遮挡，不会影响第1个输出  \n",
    "q2 = torch.tensor([[[0.1,0.1,0.1,0.1],[0.4,0.5,0.5,0.8]]])  \n",
    "k2 = q2.clone()  \n",
    "v2 = q2.clone()  \n",
    "tgt_mask = tril_mask(torch.zeros(2,2))  \n",
    "out2 = cross_attn.forward(q2,k2,v2,mask = tgt_mask)  \n",
    "print(\"out2:\\n\",out2)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedBatch():\n",
    "    def __init__(self,src,tgt,pad=0):\n",
    "        self.src = src\n",
    "        self.tgt = tgt[:,:-1]\n",
    "        self.tgt_y = tgt[:, 1:]\n",
    "        self.src_mask,self.tgt_mask = create_mask(src,tgt[:,:-1])\n",
    "        self.ntokens = (self.tgt_y!= pad).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试MaskedBatch  \n",
    "mbatch = MaskedBatch(src = src.to(device),tgt = tgt.to(device), pad = 0)  \n",
    "print(mbatch.src.shape)  \n",
    "print(mbatch.tgt.shape)  \n",
    "print(mbatch.tgt_y.shape)  \n",
    "  \n",
    "print(mbatch.src_mask.shape)  \n",
    "print(mbatch.tgt_mask.shape)  \n",
    "print(mbatch.ntokens)\n",
    "\n",
    "px.imshow(mbatch.tgt_mask.to(\"cpu\")[0],color_continuous_scale=\"blues\",width=600,height=600)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):  \n",
    "    \"Implements FFN equation.\"  \n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):  \n",
    "        super(PositionwiseFeedForward, self).__init__()  \n",
    "        self.linear1 = nn.Linear(d_model, d_ff)  #线性层默认作用在最后一维度  \n",
    "        self.linear2 = nn.Linear(d_ff, d_model)  \n",
    "        self.dropout = nn.Dropout(dropout)  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))  \n",
    "      \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforwardLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, dropout=0.1):\n",
    "        super(feedforwardLayer, self).__init__()\n",
    "        self.function1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.function2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.function2(self.dropout(F.relu(self.function1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):  \n",
    "    \"Construct a layernorm module (similar to torch.nn.LayerNorm).\"  \n",
    "    def __init__(self, features, eps=1e-6):  \n",
    "        super(LayerNorm, self).__init__()  \n",
    "        self.weight = nn.Parameter(torch.ones(features))  \n",
    "        self.bias = nn.Parameter(torch.zeros(features))  \n",
    "        self.eps = eps  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        mean = x.mean(-1, keepdim=True)  \n",
    "        std = x.std(-1, keepdim=True)  \n",
    "        return self.weight * (x - mean) / (std + self.eps) + self.bias  \n",
    "      \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConnection(nn.Module):  \n",
    "    \"\"\"  \n",
    "    A residual connection with a layer norm.  \n",
    "    Note the norm is at last according to the paper, but it may be better at first.  \n",
    "    \"\"\"  \n",
    "    def __init__(self, size, dropout, norm_first=True):  \n",
    "        super(ResConnection, self).__init__()  \n",
    "        self.norm = LayerNorm(size)  \n",
    "        self.dropout = nn.Dropout(dropout)  \n",
    "        self.norm_first = norm_first  \n",
    "  \n",
    "    def forward(self, x, sublayer):  \n",
    "        \"Apply residual connection to any sublayer with the same size.\"  \n",
    "        if self.norm_first:  \n",
    "            return x + self.dropout(sublayer(self.norm(x)))  \n",
    "        else:  \n",
    "            return self.norm(x + self.dropout(sublayer(x)))  \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resconnect_and_layernorm(nn.Module):\n",
    "    def __init__(self, size, dropout=0.1):\n",
    "        super(resconnect_and_layernorm, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        # res first and then norm\n",
    "        return self.norm(x + self.dropout(sublayer_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词嵌入  \n",
    "class WordEmbedding(nn.Module):  \n",
    "    def __init__(self, d_model, vocab):  \n",
    "        super(WordEmbedding, self).__init__()  \n",
    "        self.embedding = nn.Embedding(vocab, d_model)  \n",
    "        self.d_model = d_model  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        return self.embedding(x) * math.sqrt(self.d_model) #note here, multiply sqrt(d_model)  \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, input_dim,vocab_size):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, input_dim)\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * np.sqrt(self.input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码  \n",
    "class PositionEncoding(nn.Module):  \n",
    "    \"Implement the PE function.\"  \n",
    "    def __init__(self, d_model, dropout, max_len=5000):  \n",
    "        super(PositionEncoding, self).__init__()  \n",
    "        self.dropout = nn.Dropout(p=dropout)  \n",
    "          \n",
    "        # Compute the positional encodings once in log space.  \n",
    "        pe = torch.zeros(max_len, d_model)  \n",
    "        position = torch.arange(0, max_len).unsqueeze(1)  \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *  \n",
    "                             -(math.log(10000.0) / d_model))  \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  \n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  \n",
    "        pe = pe.unsqueeze(0)  \n",
    "        self.register_buffer('pe', pe)  \n",
    "          \n",
    "    def forward(self, x):  \n",
    "        x = x + self.pe[:, :x.size(1)]  \n",
    "        return self.dropout(x)  \n",
    "      \n",
    "# test PositionalEncoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, input_dim, max_len=5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, input_dim,device=device)\n",
    "        pos = torch.arange(0, max_len,device=device).unsqueeze(1)\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (torch.arange(0, input_dim, 2,device=device) / input_dim)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (torch.arange(0, input_dim, 2,device=device) / input_dim)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output =  x + self.encoding.unsqueeze(0)[:, :x.shape[1], :]       \n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "pe = PositionEncoding(120,0)  \n",
    "z = pe.forward(torch.zeros(1, 100, 120))  \n",
    "df = pd.DataFrame(z[0, :, [0,20,60,110]].data.numpy(),columns = [\"dim\"+c for c in ['0','20','60','110']])  \n",
    "df.insert(0,\"x\",np.arange(100))  \n",
    "px.line(df, x = \"x\",y = [\"dim\"+c for c in ['0','20','60','110']]).show()   \n",
    "\n",
    "pe = PositionalEncoding(120,dropout=0)  \n",
    "z1 = pe.forward(torch.zeros(1, 100, 120))  \n",
    "df = pd.DataFrame(z1[0, :, [0,20,60,110]].data.numpy(),columns = [\"dim\"+c for c in ['0','20','60','110']])  \n",
    "df.insert(0,\"x\",np.arange(100))  \n",
    "px.line(df, x = \"x\",y = [\"dim\"+c for c in ['0','20','60','110']]).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(np.squeeze(z.data.numpy()) ,color_continuous_scale=\"blues\",width=1000,height=800)    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):  \n",
    "    \"TransformerEncoderLayer is made up of self-attn and feed forward (defined below)\"  \n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):  \n",
    "        super(TransformerEncoderLayer, self).__init__()  \n",
    "        self.self_attn = self_attn  \n",
    "        self.feed_forward = feed_forward  \n",
    "        self.res_layers = clones(ResConnection(size, dropout), 2)  \n",
    "        self.size = size  \n",
    "  \n",
    "    def forward(self, x, mask):  \n",
    "        \"Follow Figure 1 (left) for connections.\"  \n",
    "        x = self.res_layers[0](x, lambda x: self.self_attn(x, x, x, mask))  \n",
    "        return self.res_layers[1](x, self.feed_forward)  \n",
    "      \n",
    "      \n",
    "class TransformerEncoder(nn.Module):  \n",
    "    \"TransformerEncoder is a stack of N TransformerEncoderLayer\"  \n",
    "    def __init__(self, layer, N):  \n",
    "        super(TransformerEncoder, self).__init__()  \n",
    "        self.layers = clones(layer, N)  \n",
    "        self.norm = LayerNorm(layer.size)  \n",
    "          \n",
    "    def forward(self, x, mask):  \n",
    "        \"Pass the input (and mask) through each layer in turn.\"  \n",
    "        for layer in self.layers:  \n",
    "            x = layer(x, mask)  \n",
    "        return self.norm(x)  \n",
    "      \n",
    "    @classmethod  \n",
    "    def from_config(cls,N=6,d_model=512, d_ff=2048, h=8, dropout=0.1):  \n",
    "        attn = MultiHeadAttention(h, d_model)  \n",
    "        ff = PositionwiseFeedForward(d_model, d_ff, dropout)  \n",
    "        layer = TransformerEncoderLayer(d_model, attn, ff, dropout)  \n",
    "        return cls(layer,N)  \n",
    "# from torchkeras import summary   \n",
    "  \n",
    "# src_embed = nn.Sequential(WordEmbedding(d_model=32, vocab = len(word)),   \n",
    "#                           PositionEncoding(d_model=32, dropout=0.1))  \n",
    "# encoder = TransformerEncoder.from_config(N=3,d_model=32, d_ff=128, h=8, dropout=0.1)  \n",
    "# src_mask = pad_mask(src)  \n",
    "# memory = encoder(*[src_embed(src),src_mask])   \n",
    "# summary(encoder,input_data_args = [src_embed(src),src_mask]);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_heads, input_dim, N_layer, hidden_dim, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attention = nn.ModuleList(multihead_attn(n_heads, input_dim) for _ in range(N_layer))\n",
    "        self.res_layer1 = nn.ModuleList([resconnect_and_layernorm(input_dim, dropout) for _ in range(N_layer)])\n",
    "        self.res_layer2 = nn.ModuleList([resconnect_and_layernorm(input_dim, dropout) for _ in range(N_layer)])\n",
    "        self.feedforward = nn.ModuleList([feedforwardLayer(input_dim, input_dim, hidden_dim, dropout) for _ in range(N_layer)])\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.N_layer = N_layer\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for i in range(self.N_layer):\n",
    "            x = self.res_layer1[i](x, self.self_attention[i](x, x, x, mask))\n",
    "            x = self.res_layer2[i](x, self.feedforward[i](x))\n",
    "        return self.norm(x)\n",
    "\n",
    "# from torchkeras import summary   \n",
    "  \n",
    "# src_embed = nn.Sequential(Embedding(input_dim=32, vocab_size = len(word)),   \n",
    "#                           PositionalEncoding(input_dim=32, dropout=0.1))  \n",
    "# encoder = Encoder(N_layer=3,input_dim=32, hidden_dim=128, n_heads=8, dropout=0.1)  \n",
    "# src_mask,_ = create_mask(src,tgt)\n",
    "# memory = encoder(*[src_embed(src),src_mask])   \n",
    "# summary(encoder,input_data_args = [src_embed(src),src_mask]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):  \n",
    "    \"TransformerDecoderLayer is made of self-attn, cross-attn, and feed forward (defined below)\"  \n",
    "    def __init__(self, size, self_attn, cross_attn, feed_forward, dropout):  \n",
    "        super(TransformerDecoderLayer, self).__init__()  \n",
    "        self.size = size  \n",
    "        self.self_attn = self_attn  \n",
    "        self.cross_attn = cross_attn  \n",
    "        self.feed_forward = feed_forward  \n",
    "        self.res_layers = clones(ResConnection(size, dropout), 3)  \n",
    "   \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):  \n",
    "        \"Follow Figure 1 (right) for connections.\"  \n",
    "        m = memory  \n",
    "        x = self.res_layers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))  \n",
    "        x = self.res_layers[1](x, lambda x: self.cross_attn(x, m, m, src_mask))  \n",
    "        return self.res_layers[2](x, self.feed_forward)  \n",
    "      \n",
    "class TransformerDecoder(nn.Module):  \n",
    "    \"Generic N layer decoder with masking.\"  \n",
    "    def __init__(self, layer, N):  \n",
    "        super(TransformerDecoder, self).__init__()  \n",
    "        self.layers = clones(layer, N)  \n",
    "        self.norm = LayerNorm(layer.size)  \n",
    "          \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):  \n",
    "        for layer in self.layers:  \n",
    "            x = layer(x, memory, src_mask, tgt_mask)  \n",
    "        return self.norm(x)  \n",
    "      \n",
    "    @classmethod  \n",
    "    def from_config(cls,N=6,d_model=512, d_ff=2048, h=8, dropout=0.1):  \n",
    "        self_attn = MultiHeadAttention(h, d_model)  \n",
    "        cross_attn = MultiHeadAttention(h, d_model)  \n",
    "        ff = PositionwiseFeedForward(d_model, d_ff, dropout)  \n",
    "        layer = TransformerDecoderLayer(d_model, self_attn, cross_attn, ff, dropout)  \n",
    "        return cls(layer,N)  \n",
    "  \n",
    "# from torchkeras import summary   \n",
    "  \n",
    "# mbatch = MaskedBatch(src=src,tgt=tgt,pad=0)  \n",
    "  \n",
    "# src_embed = nn.Sequential(WordEmbedding(d_model=32, vocab = len(vocab)),   \n",
    "#                           PositionEncoding(d_model=32, dropout=0.1))  \n",
    "# encoder = TransformerEncoder.from_config(N=3,d_model=32, d_ff=128, h=8, dropout=0.1)  \n",
    "# memory = encoder(src_embed(src),mbatch.src_mask)   \n",
    "  \n",
    "# tgt_embed = nn.Sequential(WordEmbedding(d_model=32, vocab = len(vocab)),   \n",
    "#                           PositionEncoding(d_model=32, dropout=0.1))  \n",
    "# decoder = TransformerDecoder.from_config(N=3,d_model=32, d_ff=128, h=8, dropout=0.1)  \n",
    "  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)   \n",
    "# summary(decoder,input_data_args = [tgt_embed(mbatch.tgt),memory,  \n",
    "#                               mbatch.src_mask,mbatch.tgt_mask]);  \n",
    "  \n",
    "# decoder.eval()   \n",
    "# mbatch.tgt[0][1]=8  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)  \n",
    "# print(torch.sum(result[0][0]))   \n",
    "  \n",
    "# mbatch.tgt[0][1]=7  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)  \n",
    "# print(torch.sum(result[0][0]))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_heads, input_dim, N_layer, hidden_dim, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attention = nn.ModuleList(multihead_attn(n_heads, input_dim) for _ in range(N_layer))\n",
    "        self.cross_attention = nn.ModuleList(multihead_attn(n_heads, input_dim) for _ in range(N_layer))\n",
    "        self.feedforward = nn.ModuleList([feedforwardLayer(input_dim, input_dim, hidden_dim, dropout) for _ in range(N_layer)])\n",
    "        self.res_layer1 = nn.ModuleList([resconnect_and_layernorm(input_dim, dropout) for _ in range(N_layer)])\n",
    "        self.res_layer2 = nn.ModuleList([resconnect_and_layernorm(input_dim, dropout) for _ in range(N_layer)])\n",
    "        self.res_layer3 = nn.ModuleList([resconnect_and_layernorm(input_dim, dropout) for _ in range(N_layer)])\n",
    "        self.N_layer = N_layer\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for i in range(self.N_layer):\n",
    "            x = self.res_layer1[i](x, self.self_attention[i](x, x, x, tgt_mask))\n",
    "            x = self.res_layer2[i](x, self.cross_attention[i](x, memory, memory, src_mask))\n",
    "            x = self.res_layer3[i](x, self.feedforward[i](x))\n",
    "        return self.norm(x)\n",
    "\n",
    "# from torchkeras import summary   \n",
    "  \n",
    "# mbatch = MaskedBatch(src=src,tgt=tgt,pad=0)  \n",
    "  \n",
    "# src_embed = nn.Sequential(Embedding(input_dim=32, vocab_size = len(vocab)),   \n",
    "#                           PositionalEncoding(input_dim=32, dropout=0.1))  \n",
    "# encoder = Encoder(N_layer=3,input_dim=32, hidden_dim=128, n_heads=8, dropout=0.1)  \n",
    "# memory = encoder(src_embed(src),mbatch.src_mask)   \n",
    "  \n",
    "# tgt_embed = nn.Sequential(Embedding(input_dim=32, vocab_size = len(vocab)),   \n",
    "#                           PositionalEncoding(input_dim=32, dropout=0.1))  \n",
    "# decoder = Decoder(N_layer=3,input_dim=32, hidden_dim=128, n_heads=8, dropout=0.1)  \n",
    "  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)   \n",
    "# summary(decoder,input_data_args = [tgt_embed(mbatch.tgt),memory,  \n",
    "#                               mbatch.src_mask,mbatch.tgt_mask]);  \n",
    "  \n",
    "# decoder.eval()   \n",
    "# mbatch.tgt[0][1]=8  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)  \n",
    "# print(torch.sum(result[0][0]))   \n",
    "  \n",
    "# mbatch.tgt[0][1]=7  \n",
    "# result = decoder.forward(tgt_embed(mbatch.tgt),memory,mbatch.src_mask,mbatch.tgt_mask)  \n",
    "# print(torch.sum(result[0][0]))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):  \n",
    "    \"Define standard linear + softmax generation step.\"  \n",
    "    def __init__(self, d_model, vocab):  \n",
    "        super(Generator, self).__init__()  \n",
    "        self.proj = nn.Linear(d_model, vocab)  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        return F.log_softmax(self.proj(x), dim=-1)  \n",
    "  \n",
    "# generator = Generator(d_model = 32, vocab = len(vocab))   \n",
    "# log_probs  = generator(result)  \n",
    "# probs = torch.exp(log_probs)  \n",
    "# print(\"output_probs.shape:\",probs.shape)  \n",
    "# print(\"sum(probs)=1:\")   \n",
    "# print(torch.sum(probs,dim = -1)[0])   \n",
    "  \n",
    "# summary(generator,input_data = result);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn   \n",
    "class Transformer(nn.Module):  \n",
    "    \"\"\"  \n",
    "    A standard Encoder-Decoder architecture. Base for this and many other models.  \n",
    "    \"\"\"  \n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):  \n",
    "        super(Transformer, self).__init__()  \n",
    "        self.encoder = encoder  \n",
    "        self.decoder = decoder  \n",
    "        self.src_embed = src_embed  \n",
    "        self.tgt_embed = tgt_embed  \n",
    "        self.generator = generator  \n",
    "        self.reset_parameters()  \n",
    "          \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):  \n",
    "        \"Take in and process masked src and target sequences.\"  \n",
    "        return self.generator(self.decode(self.encode(src, src_mask),   \n",
    "                src_mask, tgt, tgt_mask))  \n",
    "      \n",
    "    def encode(self, src, src_mask):  \n",
    "        return self.encoder(self.src_embed(src), src_mask)  \n",
    "      \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):  \n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)  \n",
    "      \n",
    "    @classmethod  \n",
    "    def from_config(cls,src_vocab,tgt_vocab,N=6,d_model=512, d_ff=2048, h=8, dropout=0.1):  \n",
    "        encoder = TransformerEncoder.from_config(N=N,d_model=d_model,  \n",
    "                  d_ff=d_ff, h=h, dropout=dropout)  \n",
    "        decoder = TransformerDecoder.from_config(N=N,d_model=d_model,  \n",
    "                  d_ff=d_ff, h=h, dropout=dropout)  \n",
    "        src_embed = nn.Sequential(WordEmbedding(d_model, src_vocab), PositionEncoding(d_model, dropout))  \n",
    "        tgt_embed = nn.Sequential(WordEmbedding(d_model, tgt_vocab), PositionEncoding(d_model, dropout))  \n",
    "          \n",
    "        generator = Generator(d_model, tgt_vocab)  \n",
    "        return cls(encoder, decoder, src_embed, tgt_embed, generator)  \n",
    "      \n",
    "    def reset_parameters(self):  \n",
    "        for p in self.parameters():  \n",
    "            if p.dim() > 1:  \n",
    "                nn.init.xavier_uniform_(p)  \n",
    "      \n",
    "# from torchkeras import summary   \n",
    "# net = Transformer.from_config(src_vocab = len(word),tgt_vocab = len(vocab),  \n",
    "#                    N=2, d_model=32, d_ff=128, h=8, dropout=0.1)  \n",
    "  \n",
    "# mbatch = MaskedBatch(src=src,tgt=tgt,pad=0)  \n",
    "  \n",
    "# summary(net,input_data_args = [mbatch.src,mbatch.tgt,mbatch.src_mask,mbatch.tgt_mask]);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注1：此处通过继承方法将学习率调度策略融入Optimizer  \n",
    "#注2：NoamOpt中的Noam是论文作者之一的名字  \n",
    "#注3：学习率是按照step而非epoch去改变的  \n",
    "  \n",
    "class NoamOpt(torch.optim.AdamW):  \n",
    "    def __init__(self, params, model_size=512, factor=1.0, warmup=4000,   \n",
    "                 lr=0, betas=(0.9, 0.98), eps=1e-9,  \n",
    "                 weight_decay=0, amsgrad=False):  \n",
    "        super(NoamOpt,self).__init__(params, lr=lr, betas=betas, eps=eps,  \n",
    "                 weight_decay=weight_decay, amsgrad=amsgrad)  \n",
    "        self._step = 0  \n",
    "        self.warmup = warmup  \n",
    "        self.factor = factor  \n",
    "        self.model_size = model_size  \n",
    "          \n",
    "    def step(self,closure=None):  \n",
    "        \"Update parameters and rate\"  \n",
    "        self._step += 1  \n",
    "        rate = self.rate()  \n",
    "        for p in self.param_groups:  \n",
    "            p['lr'] = rate  \n",
    "        super(NoamOpt,self).step(closure=closure)  \n",
    "          \n",
    "    def rate(self, step = None):  \n",
    "        \"Implement `lrate` above\"  \n",
    "        if step is None:  \n",
    "            step = self._step  \n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *  \n",
    "            min(step * self.warmup ** (-1.5),step ** (-0.5)))  \n",
    "      \n",
    "# optimizer = NoamOpt(net.parameters(),   \n",
    "#        model_size=net.src_embed[0].d_model, factor=1.0,   \n",
    "#         warmup=400)  \n",
    "  \n",
    "# import plotly.express as px   \n",
    "  \n",
    "# opts = [NoamOpt(net.parameters(),model_size=512, factor =1, warmup=4000),   \n",
    "#         NoamOpt(net.parameters(),model_size=512, factor=1,  warmup=8000),  \n",
    "#         NoamOpt(net.parameters(),model_size=256, factor=1,  warmup=4000)]  \n",
    "  \n",
    "# steps = np.arange(1, 20000)  \n",
    "# rates = [[opt.rate(i) for opt in opts] for i in steps]  \n",
    "# dfrates = pd.DataFrame(rates,columns = [\"512:4000\", \"512:8000\", \"256:4000\"])  \n",
    "# dfrates[\"steps\"] = steps   \n",
    "  \n",
    "# fig = px.line(dfrates,x=\"steps\",y=[\"512:4000\", \"512:8000\", \"256:4000\"])  \n",
    "# fig.layout.yaxis.title = \"lr\"  \n",
    "# fig   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):  \n",
    "    \"Implement label smoothing.\"  \n",
    "    def __init__(self, size, padding_idx, smoothing=0.0): #size为词典大小  \n",
    "        super(LabelSmoothingLoss, self).__init__()  \n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")  \n",
    "        self.padding_idx = padding_idx  \n",
    "        self.confidence = 1.0 - smoothing  \n",
    "        self.smoothing = smoothing  \n",
    "        self.size = size  \n",
    "        self.true_dist = None  \n",
    "          \n",
    "    def forward(self, x, target):  \n",
    "        assert x.size(1) == self.size  \n",
    "        true_dist = x.data.clone()  \n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))  #预测结果不会是<SOS> #和<PAD>  \n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)  \n",
    "        true_dist[:, self.padding_idx] = 0  \n",
    "        mask = torch.nonzero((target.data == self.padding_idx).int())  \n",
    "        if mask.dim() > 0:  \n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)  \n",
    "        self.true_dist = true_dist  \n",
    "        return self.criterion(x, true_dist)  \n",
    "      \n",
    "# # Example of label smoothing.  \n",
    "# smooth_loss = LabelSmoothingLoss(5, 0, 0.4)  \n",
    "# predict = torch.FloatTensor([[1e-10, 0.2, 0.7, 0.1, 1e-10],  \n",
    "#                              [1e-10, 0.2, 0.7, 0.1, 1e-10],   \n",
    "#                              [1e-10, 0.2, 0.7, 0.1, 1e-10]])  \n",
    "# loss = smooth_loss(predict.log(), torch.LongTensor([2, 1, 0]))  \n",
    "  \n",
    "# print(\"smoothed target:\\n\",smooth_loss.true_dist,\"\\n\")   \n",
    "# print(\"loss:\",loss)  \n",
    "# px.imshow(smooth_loss.true_dist,color_continuous_scale=\"blues\",height=600,width=1000)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整体流程试算  \n",
    "  \n",
    "for src,tgt in dl_train:  \n",
    "    break   \n",
    "mbatch = MaskedBatch(src=src,tgt=tgt,pad = 0)  \n",
    "  \n",
    "net = Transformer.from_config(src_vocab = len(vocab),tgt_vocab = len(vocab),  \n",
    "                   N=3, d_model=64, d_ff=128, h=8, dropout=0.1)  \n",
    "  \n",
    "#loss  \n",
    "loss_fn = LabelSmoothingLoss(size=len(vocab),   \n",
    "            padding_idx=0, smoothing=0.2)  \n",
    "preds = net.forward(mbatch.src, mbatch.tgt, mbatch.src_mask, mbatch.tgt_mask)  \n",
    "preds = preds.reshape(-1, preds.size(-1))  \n",
    "labels = mbatch.tgt_y.reshape(-1)  \n",
    "loss = loss_fn(preds, labels)/mbatch.ntokens   \n",
    "print('loss=',loss.item())                               \n",
    "  \n",
    "#metric  \n",
    "preds = preds.argmax(dim=-1).view(-1)[labels!=0]  \n",
    "labels = labels[labels!=0]  \n",
    "  \n",
    "acc = (preds==labels).sum()/(labels==labels).sum()  \n",
    "print('acc=',acc.item())  \n",
    "  \n",
    "  \n",
    "from torchmetrics import Accuracy   \n",
    "#使用torchmetrics中的指标  \n",
    "accuracy = Accuracy(task='multiclass',num_classes=len(vocab))  \n",
    "accuracy.update(preds,labels)  \n",
    "print('acc=',accuracy.compute().item())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整体流程试算  \n",
    "# test\n",
    "  \n",
    "for src,tgt in dl_train:  \n",
    "    break   \n",
    "mbatch = MaskedBatch(src=src,tgt=tgt,pad = 0)  \n",
    "  \n",
    "net = Transformer(Encoder(N_layer=3,input_dim=64, hidden_dim=128, n_heads=8, dropout=0.1),\n",
    "                  Decoder(N_layer=3,input_dim=64, hidden_dim=128, n_heads=8, dropout=0.1),  \n",
    "                    nn.Sequential(Embedding(input_dim=64, vocab_size = len(vocab)),   \n",
    "                            PositionalEncoding(input_dim=64, dropout=0.1)),\n",
    "                    nn.Sequential(Embedding(input_dim=64, vocab_size = len(vocab)),\n",
    "                            PositionalEncoding(input_dim=64, dropout=0.1)),\n",
    "                        Generator(d_model=64, vocab=len(vocab)))\n",
    "  \n",
    "#loss  \n",
    "loss_fn = LabelSmoothingLoss(size=len(vocab),   \n",
    "            padding_idx=0, smoothing=0.2)  \n",
    "preds = net.forward(mbatch.src, mbatch.tgt, mbatch.src_mask, mbatch.tgt_mask)  \n",
    "preds = preds.reshape(-1, preds.size(-1))  \n",
    "labels = mbatch.tgt_y.reshape(-1)  \n",
    "loss = loss_fn(preds, labels)/mbatch.ntokens   \n",
    "print('loss=',loss.item())                               \n",
    "  \n",
    "#metric  \n",
    "preds = preds.argmax(dim=-1).view(-1)[labels!=0]  \n",
    "labels = labels[labels!=0]  \n",
    "  \n",
    "acc = (preds==labels).sum()/(labels==labels).sum()  \n",
    "print('acc=',acc.item())  \n",
    "  \n",
    "  \n",
    "from torchmetrics import Accuracy   \n",
    "#使用torchmetrics中的指标  \n",
    "accuracy = Accuracy(task='multiclass',num_classes=len(vocab))  \n",
    "accuracy.update(preds,labels)  \n",
    "print('acc=',accuracy.compute().item())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "\n",
    "from torchkeras import KerasModel   \n",
    "  \n",
    "class StepRunner:  \n",
    "    def __init__(self, net, loss_fn,   \n",
    "                 accelerator=None, stage = \"train\", metrics_dict = None,   \n",
    "                 optimizer = None, lr_scheduler = None  \n",
    "                 ):  \n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage  \n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler  \n",
    "        self.accelerator = accelerator  \n",
    "        if self.stage=='train':  \n",
    "            self.net.train()   \n",
    "        else:  \n",
    "            self.net.eval()  \n",
    "      \n",
    "    def __call__(self, batch):  \n",
    "        src,tgt = batch   \n",
    "        mbatch = MaskedBatch(src=src,tgt=tgt,pad = 0)  \n",
    "          \n",
    "        #loss  \n",
    "        with self.accelerator.autocast():  \n",
    "            preds = net.forward(mbatch.src, mbatch.tgt, mbatch.src_mask, mbatch.tgt_mask)  \n",
    "            preds = preds.reshape(-1, preds.size(-1))  \n",
    "            labels = mbatch.tgt_y.reshape(-1)  \n",
    "            loss = loss_fn(preds, labels)/mbatch.ntokens   \n",
    "              \n",
    "            #filter padding  \n",
    "            preds = preds.argmax(dim=-1).view(-1)[labels!=0]  \n",
    "            labels = labels[labels!=0]  \n",
    "  \n",
    "  \n",
    "        #backward()  \n",
    "        if self.stage==\"train\" and self.optimizer is not None:  \n",
    "            self.accelerator.backward(loss)  \n",
    "            if self.accelerator.sync_gradients:  \n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)  \n",
    "            self.optimizer.step()  \n",
    "            if self.lr_scheduler is not None:  \n",
    "                self.lr_scheduler.step()  \n",
    "            self.optimizer.zero_grad()  \n",
    "              \n",
    "        all_loss = self.accelerator.gather(loss).sum()  \n",
    "        all_preds = self.accelerator.gather(preds)  \n",
    "        all_labels = self.accelerator.gather(labels)  \n",
    "          \n",
    "          \n",
    "        #losses (or plain metrics that can be averaged)  \n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}  \n",
    "  \n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(all_preds, all_labels).item()   \n",
    "                        for name,metric_fn in self.metrics_dict.items()}  \n",
    "          \n",
    "        if self.stage==\"train\":  \n",
    "            if self.optimizer is not None:  \n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']  \n",
    "            else:  \n",
    "                step_metrics['lr'] = 0.0  \n",
    "        return step_losses,step_metrics  \n",
    "      \n",
    "KerasModel.StepRunner = StepRunner   \n",
    "  \n",
    "from torchmetrics import Accuracy   \n",
    "  \n",
    "net = Transformer(Encoder(N_layer=5,input_dim=64, hidden_dim=128, n_heads=8, dropout=0.1),\n",
    "                  Decoder(N_layer=5,input_dim=64, hidden_dim=128, n_heads=8, dropout=0.1),  \n",
    "                    nn.Sequential(Embedding(input_dim=64, vocab_size = len(vocab)),   \n",
    "                            PositionalEncoding(input_dim=64, dropout=0.1)),\n",
    "                    nn.Sequential(Embedding(input_dim=64, vocab_size = len(vocab)),\n",
    "                            PositionalEncoding(input_dim=64, dropout=0.1)),\n",
    "                        Generator(d_model=64, vocab=len(vocab)))\n",
    "\n",
    "net.to(device)\n",
    "  \n",
    "loss_fn = LabelSmoothingLoss(size=len(vocab),   \n",
    "            padding_idx=0, smoothing=0.1)  \n",
    "  \n",
    "metrics_dict = {'acc':Accuracy(task='multiclass',num_classes=len(vocab))}   \n",
    "optimizer = NoamOpt(net.parameters(),model_size=64)  \n",
    "  \n",
    "model = KerasModel(net,  \n",
    "                   loss_fn=loss_fn,  \n",
    "                   metrics_dict=metrics_dict,  \n",
    "                   optimizer = optimizer)  \n",
    "  \n",
    "model.fit(  \n",
    "    train_data=dl_train,  \n",
    "    val_data=dl_val,  \n",
    "    epochs=100,  \n",
    "    ckpt_path='checkpoint',  \n",
    "    patience=10,  \n",
    "    monitor='val_acc',  \n",
    "    mode='max',  \n",
    "    callbacks=None,  \n",
    "    plot=True  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel   \n",
    "  \n",
    "class StepRunner:  \n",
    "    def __init__(self, net, loss_fn,   \n",
    "                 accelerator=None, stage = \"train\", metrics_dict = None,   \n",
    "                 optimizer = None, lr_scheduler = None  \n",
    "                 ):  \n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage  \n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler  \n",
    "        self.accelerator = accelerator  \n",
    "        if self.stage=='train':  \n",
    "            self.net.train()   \n",
    "        else:  \n",
    "            self.net.eval()  \n",
    "      \n",
    "    def __call__(self, batch):  \n",
    "        src,tgt = batch   \n",
    "        mbatch = MaskedBatch(src=src,tgt=tgt,pad = 0)  \n",
    "          \n",
    "        #loss  \n",
    "        with self.accelerator.autocast():  \n",
    "            preds = net.forward(mbatch.src, mbatch.tgt, mbatch.src_mask, mbatch.tgt_mask)  \n",
    "            preds = preds.reshape(-1, preds.size(-1))  \n",
    "            labels = mbatch.tgt_y.reshape(-1)  \n",
    "            loss = loss_fn(preds, labels)/mbatch.ntokens   \n",
    "              \n",
    "            #filter padding  \n",
    "            preds = preds.argmax(dim=-1).view(-1)[labels!=0]  \n",
    "            labels = labels[labels!=0]  \n",
    "  \n",
    "  \n",
    "        #backward()  \n",
    "        if self.stage==\"train\" and self.optimizer is not None:  \n",
    "            self.accelerator.backward(loss)  \n",
    "            if self.accelerator.sync_gradients:  \n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)  \n",
    "            self.optimizer.step()  \n",
    "            if self.lr_scheduler is not None:  \n",
    "                self.lr_scheduler.step()  \n",
    "            self.optimizer.zero_grad()  \n",
    "              \n",
    "        all_loss = self.accelerator.gather(loss).sum()  \n",
    "        all_preds = self.accelerator.gather(preds)  \n",
    "        all_labels = self.accelerator.gather(labels)  \n",
    "          \n",
    "          \n",
    "        #losses (or plain metrics that can be averaged)  \n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}  \n",
    "  \n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(all_preds, all_labels).item()   \n",
    "                        for name,metric_fn in self.metrics_dict.items()}  \n",
    "          \n",
    "        if self.stage==\"train\":  \n",
    "            if self.optimizer is not None:  \n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']  \n",
    "            else:  \n",
    "                step_metrics['lr'] = 0.0  \n",
    "        return step_losses,step_metrics  \n",
    "      \n",
    "KerasModel.StepRunner = StepRunner   \n",
    "  \n",
    "from torchmetrics import Accuracy   \n",
    "  \n",
    "net = Transformer.from_config(src_vocab = len(vocab),tgt_vocab = len(vocab),  \n",
    "                   N=5, d_model=64, d_ff=128, h=8, dropout=0.1)  \n",
    "\n",
    "\n",
    "  \n",
    "loss_fn = LabelSmoothingLoss(size=len(vocab),   \n",
    "            padding_idx=0, smoothing=0.1)  \n",
    "  \n",
    "metrics_dict = {'acc':Accuracy(task='multiclass',num_classes=len(vocab))}   \n",
    "optimizer = NoamOpt(net.parameters(),model_size=64)  \n",
    "  \n",
    "model = KerasModel(net,  \n",
    "                   loss_fn=loss_fn,  \n",
    "                   metrics_dict=metrics_dict,  \n",
    "                   optimizer = optimizer)  \n",
    "  \n",
    "model.fit(  \n",
    "    train_data=dl_train,  \n",
    "    val_data=dl_val,  \n",
    "    epochs=100,  \n",
    "    ckpt_path='checkpoint',  \n",
    "    patience=10,  \n",
    "    monitor='val_acc',  \n",
    "    mode='max',  \n",
    "    callbacks=None,  \n",
    "    plot=True  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(net, src, src_mask, max_len, start_symbol):  \n",
    "    net.eval()   \n",
    "    memory = net.encode(src, src_mask)  \n",
    "    ys = torch.full((len(src),max_len),start_symbol,dtype = src.dtype).to(src.device)  \n",
    "    for i in range(max_len-1):  \n",
    "        out = net.generator(net.decode(memory, src_mask,   \n",
    "              ys, tril_mask(ys)))  \n",
    "        ys[:,i+1]=out.argmax(dim=-1)[:,i]  \n",
    "    return ys  \n",
    "  \n",
    "def get_raw_words(tensor,vocab_r) ->\"str\":  \n",
    "    words = [vocab_r[i] for i in tensor.tolist()]  \n",
    "    return words  \n",
    "  \n",
    "def get_words(tensor,vocab_r) ->\"str\":  \n",
    "    s = \"\".join([vocab_r[i] for i in tensor.tolist()])  \n",
    "    words = s[:s.find('<EOS>')].replace('<SOS>','')  \n",
    "    return words  \n",
    "  \n",
    "def prepare(x,accelerator=model.accelerator):  \n",
    "    return x.to(accelerator.device)  \n",
    "##解码翻译结果  \n",
    "net = model.net  \n",
    "net.eval()   \n",
    "net = prepare(net)  \n",
    "src,tgt = get_data()  \n",
    "src,tgt = prepare(src),prepare(tgt)  \n",
    "mbatch = MaskedBatch(src=src.unsqueeze(dim=0),tgt=tgt.unsqueeze(dim=0))  \n",
    "  \n",
    "y_pred = greedy_decode(net,mbatch.src,mbatch.src_mask,50,vocab[\"<SOS>\"])  \n",
    "print(\"input:\")  \n",
    "print(get_words(mbatch.src[0],vocab_r),'\\n') #标签结果  \n",
    "print(\"ground truth:\")  \n",
    "print(get_words(mbatch.tgt[0],vocab_r),'\\n') #标签结果  \n",
    "print(\"prediction:\")  \n",
    "print(get_words(y_pred[0],vocab_r)) #解码预测结果，原始标签中<PAD>位置的预测可以忽略  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  \n",
    "  \n",
    "net = prepare(net)  \n",
    "loop = tqdm(range(1,201))  \n",
    "correct = 0  \n",
    "for i in loop:  \n",
    "    src,tgt = get_data()  \n",
    "    src,tgt = prepare(src),prepare(tgt)  \n",
    "    mbatch = MaskedBatch(src=src.unsqueeze(dim=0),tgt=tgt.unsqueeze(dim=0))  \n",
    "    y_pred = greedy_decode(net,mbatch.src,mbatch.src_mask,50,vocab[\"<SOS>\"])  \n",
    "  \n",
    "    inputs = get_words(mbatch.src[0],vocab_r) #标签结果  \n",
    "    gt = get_words(mbatch.tgt[0],vocab_r) #标签结果  \n",
    "    preds = get_words(y_pred[0],vocab_r) #解码预测结果，原始标签中<PAD>位置的预测可以忽略  \n",
    "    if preds==gt:  \n",
    "        correct+=1  \n",
    "    loop.set_postfix(acc = correct/i)  \n",
    "      \n",
    "print(\"acc=\",correct/len(loop))  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
